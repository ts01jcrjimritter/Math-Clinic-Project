{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spire_Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Nio\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = 2018\n",
    "start_date = 1101\n",
    "end_date = 1131\n",
    "hhmm = '0600'\n",
    "fcs = '006'\n",
    "\n",
    "fdata = []\n",
    "lat = []\n",
    "lon = []\n",
    "date1 = [[[]]]\n",
    "ele = [1, 2, 3]\n",
    "la = 0\n",
    "lat_init = 90.0\n",
    "while la < 361:\n",
    "    lat.append(lat_init)\n",
    "    la += 1\n",
    "    lat_init -= .5\n",
    "    \n",
    "lo = 0\n",
    "lon_init = 0.0\n",
    "while lo < 720:\n",
    "    lon.append(lon_init)\n",
    "    lo += 1\n",
    "    lon_init += .5\n",
    "\n",
    "bottom = 107           #  Set limits for Latitudes\n",
    "top = 98              #  and Longitudes in \n",
    "right = 504            #  in Colorado  to limit the \n",
    "left = 518             #  volume of data\n",
    "fdata=[[ele[0],lat[0],lon[0],99.0,99.0,99.0,99.0,start_date]]\n",
    "for date in range(start_date,end_date):\n",
    "    t = \"\"\n",
    "    a = ['/home/jovyan/spire/Input_Data/gfs_4_2018',str(date),'_',str(hhmm),'_',str(fcs),'.grb2']\n",
    "    file1 = t.join(a) \n",
    "    file_name = file1\n",
    "    header_file = Nio.open_file(file_name, \"r\", format=\"grib\")\n",
    "    fdata3 = header_file.variables['VGRD_P0_L103_GLL0'][0:3,0:,0:]\n",
    "    fdata4 = header_file.variables['TMP_P0_L1_GLL0'][0:,0:]\n",
    "    fdata5 = header_file.variables['DPT_P0_L103_GLL0'][0:,0:]\n",
    "    fdata6 = header_file.variables['RH_P0_L4_GLL0'][0:,0:]\n",
    "    la = top\n",
    "    el = 0\n",
    "    \n",
    "    \n",
    "    while la < bottom:\n",
    "        lo = right\n",
    "        #print('la loop')\n",
    "        #print(la)\n",
    "        while lo < left:\n",
    "            #print('lo loop')\n",
    "            #print(lo)\n",
    "            el = 0\n",
    "            while el < 1:\n",
    "                #print('ele loop')\n",
    "                fdata2=[ele[el],lat[la],lon[lo],fdata3[el,la,lo],fdata4[la,lo],fdata5[la,lo],fdata6[la,lo],date]\n",
    "                #fdata2=[ele[el],lat[la],lon[lo]]\n",
    "                fdata.append(fdata2)\n",
    "                el +=1\n",
    "        \n",
    "            lo += 1\n",
    "        la += 1\n",
    "del fdata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Elevation\",\"Latitude\",\"Longitude\",\"Wind Speed\",\"Temp\",\"Dew Point\",\"Rel Humidity\",\"Date\"]\n",
    "print(tabulate(fdata,headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Forecast_Output_pickle', 'wb') as f:\n",
    "    pickle.dump(fdata,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   pandas as  pd # Assign spreadsheet filename to `file`\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Start_Date to the first date \n",
    "#Set End_Date to the day after the last date\n",
    "#Initialize array for mydata \n",
    "#Read the files with observation data.\n",
    "mydata = [['Stat',0,0,99,1200,22,33,44,55]]\n",
    "\n",
    "Start_Date = 1101\n",
    "End_Date = 1131\n",
    "for date in range(Start_Date,End_Date):\n",
    "    t = \"\"\n",
    "    a = ['/home/jovyan/spire/Input_Data/obs2018',str(date),'.xlsx']\n",
    "    file1 = t.join(a) \n",
    "    file = file1\n",
    "    # \n",
    "    xl = pd.ExcelFile(file) # Print the sheet names\n",
    "    #print(xl.sheet_names) # Load a sheet into a DataFrame by name: df1\n",
    "    df1 = xl.parse('Sheet1')\n",
    "    df = pd.read_excel(file, sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "    #print(\"Column headings:\")\n",
    "    StationID = df['Station ID']\n",
    "    Latitude = df['Latitude']\n",
    "    Longitude = df['Longitude']\n",
    "    Elevation = df['Elevation']\n",
    "    Time = df['Time']\n",
    "    Temperature = df['Temperature']\n",
    "    U = df['U']\n",
    "    V = df['V']\n",
    "    WindSpeed = df['Wind Speed']\n",
    "    Visibility = df['Visibility']\n",
    "    Ceiling = df['Ceiling']\n",
    "    #print(df.columns)\n",
    "    #for i in range(10):\n",
    "    #   print '%-12i%-12i' % (10 ** i, 20 ** i)\n",
    "    #print(\"Station ID   Latitude  Longitude  Elevation Time                 Temperature   U   V   Wind Speed \")\n",
    "\n",
    "    i = 0\n",
    "    #while loop to build array\n",
    "    while i < len(df):\n",
    "        mydata2=[StationID[i],Latitude[i],Longitude[i],Elevation[i],Time[i],Temperature[i],U[i],V[i],WindSpeed[i]]\n",
    "        mydata.append(mydata2)\n",
    "        i+=1     \n",
    "del mydata[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Observation_Output_pickle', 'wb') as f:\n",
    "    pickle.dump(mydata,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   pandas as  pd # Assign spreadsheet filename to `file`\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from operator import itemgetter, attrgetter, methodcaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the observation file in from a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Observation_Output_pickle', 'rb') as f:\n",
    "    mydata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"St ID\",\"Lat\",\"Lon\",\"Elev\", \"Time\",\"Temp\",\"U\",\"V\",\"Wind Speed\"]\n",
    "print(tabulate(mydata[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array(mydata)\n",
    "x5 = np.array(x2[0:,1:10])\n",
    "x5a = np.array(x2[0:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"Elev\", \"Time\",\"Temp\",\"U\",\"V\",\"Wind Speed\"]\n",
    "print(tabulate(x5[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file with lat, lon, grid lat, grid lon, and all observed variables\n",
    "j = 0\n",
    "i = 0\n",
    "m = len(x5)\n",
    "n = 10\n",
    "x6 = np.array(x5[0:,0:])\n",
    "#x6 = [[0 for x in range(m)] for y in range(n)]\n",
    "\n",
    "for i in range(len(x5)):\n",
    "    x6[i,0] = x5[i,0]\n",
    "    x6[i,1] = x5[i,1]\n",
    "    x6[i,4] = x5[i,2]\n",
    "    #x6[i,5] = x5[i,3]\n",
    "    #x6[i,5] = 00.0\n",
    "    x6[i,6] = x5[i,4]\n",
    "    x6[i,7] = x5[i,5]\n",
    "    #x6[i,8] = x5[i,6]\n",
    "    #x6[i,9] = x5[i,7]\n",
    "    a=x6[i,0]\n",
    "    c = a - (a % 1)\n",
    "   \n",
    "    if x6[i,0] - c < .25:\n",
    "        x6[i,2] = c\n",
    "    elif x6[i,0] - c < .5:\n",
    "        x6[i,2] = a + (.5 -(a % 1))\n",
    "    elif x6[i,0] - c < .75:\n",
    "        x6[i,2] = a + (.5 -(a % 1))\n",
    "    else:\n",
    "        x6[i,2] = a + (1 - (a % 1))\n",
    "    \n",
    "    b=x6[i,1]\n",
    "    d = b - (b % 1)\n",
    "  \n",
    "    if x6[i,1] - d < .25:\n",
    "        x6[i,3] = d\n",
    "    elif x6[i,1] - d < .5:\n",
    "        x6[i,3] = b + (.5 -(b % 1))\n",
    "    elif x6[i,1] - d < .75:\n",
    "        x6[i,3] = b + (.5 -(b % 1))\n",
    "    else:\n",
    "        x6[i,3] = b + (1 - (b %1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "x7 = [[0.0,0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "while i < len(x6):\n",
    "    xa=[x6[i,0],x6[i,1],x6[i,2],x6[i,3],x6[i,4],x5[i,3],x6[i,6],x6[i,7],x5[i,6],x5[i,7]]\n",
    "    x7.append(xa)\n",
    "    i+=1     \n",
    "del x7[0]\n",
    "x7a = np.array(x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "x7 = [[0.0,0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "while i < len(x6):\n",
    "    xa=[x6[i,0],x6[i,1],x6[i,2],x6[i,3],x6[i,4],x5[i,3],x6[i,6],x6[i,7],x5[i,6],x5[i,7]]\n",
    "    x7.append(xa)\n",
    "    i+=1     \n",
    "del x7[0]\n",
    "x7a = np.array(x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x8 = [[0.0,0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "x8a = [0.0,0.0,0.0,0.0,99,1200,22,33,44,55]\n",
    "j=0\n",
    "i=0\n",
    "for i in range(len(x7)):\n",
    "    if x7a[i,9] == 1e+11:\n",
    "        ii = 2\n",
    "    elif x7a[i,5].hour != 12:\n",
    "        ii = 2\n",
    "    else:\n",
    "        x8a = x7[i]\n",
    "        x8.append(x8a)\n",
    "        j +=1\n",
    "del x8[0]\n",
    "x8b = np.array(x8)\n",
    "x8c = np.array(x8b[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"Lat\",\"Lon\",\"Grid_Lat\",\"Grid_Lon\",\"Elev\",\"Time\",\"Temp\",\"U\",\"V\",\"Wind Sp\"]\n",
    "print(tabulate(x8c[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file with lat, lon, 4 surroundong Grid lat points, and all observed variables\n",
    "j = 0\n",
    "i = 0\n",
    "m = len(x5)\n",
    "n = 10\n",
    "x10 = np.array(x5[0:,0:])\n",
    "#x6 = [[0 for x in range(m)] for y in range(n)]\n",
    "\n",
    "for i in range(len(x5)):\n",
    "    x10[i,0] = x5[i,0]\n",
    "    x10[i,1] = x5[i,1]\n",
    "    #x10[i,6] = x5[i,2]\n",
    "    #\n",
    "    #\n",
    "    #x10[i,7] = x5[i,4]\n",
    "    #x10[i,8] = x5[i,5]\n",
    "    #\n",
    "    #\n",
    "    a=x10[i,0]            # Calculate the grid latitudes above and below each station latitude\n",
    "    c = a - (a % 1)\n",
    "   \n",
    "    if x10[i,0] - c < .5:   # find the latitude above and below\n",
    "        x10[i,2] = c\n",
    "        x10[i,4] = c + .5\n",
    "    else:\n",
    "        x10[i,2] = c + .5\n",
    "        x10[i,4] = c + 1\n",
    " \n",
    "    \n",
    "    b=x10[i,1]          # Calculate the grid longitudes to the right and left of each station longitude\n",
    "    d = b - (b % 1)\n",
    "  \n",
    "    if x10[i,0] - d < .5:    # find the longitude to the right and left\n",
    "        x10[i,3] = d\n",
    "        x10[i,5] = d + .5\n",
    "    else:\n",
    "        x10[i,3] = d + .5\n",
    "        x10[i,5] = d + 1\n",
    "        \n",
    "    if x10[i,0] - x10[i,2] < .25:   # find the closest grid lat\n",
    "        x10[i,6] = x10[i,2]\n",
    "    else:\n",
    "        x10[i,6] = x10[i,4]\n",
    "        \n",
    "    if x10[i,1] - x10[i,3] < .25:  # find the closest grid lon\n",
    "        x10[i,7] = x10[i,3]\n",
    "    else:\n",
    "        x10[i,7] = x10[i,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "x11 = [[0.0,0.0,0.0,0.0,0.0, 0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "while i < len(x6):\n",
    "    xa=[x10[i,0],x10[i,1],x10[i,2],x10[i,3],x10[i,4],x10[i,5],x10[i,6],x10[i,7],x5[i,2],x5[i,3],x5[i,4],x5[i,5],x5[i,6],x5[i,7]]\n",
    "    x11.append(xa)\n",
    "    i+=1     \n",
    "del x11[0]\n",
    "x11a = np.array(x11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"Lat\",\"Lon\",\"Gla1\",\"Glo1\",\"Gla2\",\"Glo2\",\"CLa1\",\"CLo1\",\"Elev\",\"Time\",\"Temp\",\"U\",\"V\",\"Wind Sp\"]\n",
    "print(tabulate(x11[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x12 = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "x12a = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,99,1200,22,33,44,55]\n",
    "j=0\n",
    "i=0\n",
    "for i in range(len(x11)):\n",
    "    if x11a[i,13] == 1e+11:\n",
    "        ii = 2\n",
    "    elif x11a[i,9].hour != 12:\n",
    "        ii = 2\n",
    "    else:\n",
    "        x12a = x11a[i]\n",
    "        x12.append(x12a)\n",
    "        j +=1\n",
    "del x12[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"Lat\",\"Lon\",\"Gla1\",\"Glo1\",\"Gla2\",\"Glo2\",\"CLa1\",\"CLo1\",\"Elev\",\"Time\",\"Temp\",\"U\",\"V\",\"Wind Sp\"]\n",
    "print(tabulate(x12[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13 = sorted(x12, key=itemgetter(0,1))  #Sort by lat and lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"Lat\",\"Lon\",\"Gla1\",\"Glo1\",\"Gla2\",\"Glo2\",\"CLa1\",\"CLo1\",\"Elev\",\"Time\",\"Temp\",\"U\",\"V\",\"Wind Sp\"]\n",
    "print(tabulate(x13[0:10],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x13a = np.array(x13)\n",
    "x14 = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,99,1200,22,33,44,55]]\n",
    "x14a = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,99,1200,22,33,44,55]\n",
    "j= len(x13) - 1\n",
    "i=0\n",
    "for i in range(j):\n",
    "    if (x13a[i,0] == x13a[i+1,0] and x13a[i,1] == x13a[i+1,1]):\n",
    "        i += 1\n",
    "    else:\n",
    "        x14a = x13[i]\n",
    "        x14.append(x14a)\n",
    "        i +=1\n",
    "del x14[0]\n",
    "x15a = np.array(x14)\n",
    "x15 = np.array(x15a[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"Lat\",\"Lon\",\"Gla1\",\"Glo1\",\"Gla2\",\"Glo2\",\"CLa1\",\"CLo1\",\"Elev\",\"Time\",\"Temp\",\"U\",\"V\",\"Wind Sp\"]\n",
    "print(tabulate(x15[0:10],headers=headers))   #one record for each Station Location,  sorted by lat and lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corr__Output_pickle', 'wb') as f:\n",
    "    pickle.dump(x8,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corrx6__Output_pickle', 'wb') as f:\n",
    "    pickle.dump(x6,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corrx13__Output_pickle', 'wb') as f:\n",
    "    pickle.dump(x13,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corrx15__Output_pickle', 'wb') as f:\n",
    "    pickle.dump(x15,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the forecast file in from a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Forecast_Output_pickle', 'rb') as f:\n",
    "    fdata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the station location file in from a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corrx15__Output_pickle', 'rb') as f:\n",
    "   x15 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load the observation file in from a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Grid_Corrx13__Output_pickle', 'rb') as f:\n",
    "   x13 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Elevation\",\"Latitude\",\"Longitude\",\"Wind Speed\",\"Temp\",\"Dew Point\",\"Rel Humidity\",\"Date\"]\n",
    "print(tabulate(fdata[0:10],headers=headers))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata2 = sorted(fdata, key=itemgetter(7,1,2))  #Sort by date, lat, and then lo\n",
    "fdata2a = np.array(fdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Elevation\",\"Latitude\",\"Longitude\",\"Wind Speed\",\"Temp\",\"Dew Point\",\"Rel Humidity\",\"Date\"]\n",
    "print(tabulate(fdata2[0:200],headers=headers))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import percentile\n",
    "quartiles = percentile(fdata2[3], [25, 50, 75])\n",
    "#data=fdata2[3]\n",
    "#data_min, data_max = data.min(), data.max()\n",
    "#print('Min: %.3f' % data_min)\n",
    "print('Q1: %.3f' % quartiles[0])\n",
    "print('Median: %.3f' % quartiles[1])\n",
    "print('Q3: %.3f' % quartiles[2])\n",
    "#print('Max: %.3f' % data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"GLat1\",\"GLon1\",\"GLat2\",\"GLon2\",\"CLat\",\"CLon\",\"Elev\",\"Time\",\"Elev\", \"U\", \"V\", \"WindSp\" ]\n",
    "print(tabulate(x13[0:10],headers=headers))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"GLat1\",\"GLon1\",\"GLat2\",\"GLon2\",\"CLat\",\"CLon\"]\n",
    "print(tabulate(x15[0:10],headers=headers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"GLat1\",\"GLon1\",\"GLat2\",\"GLon2\",\"CLat\",\"CLon\"]\n",
    "print(tabulate(x15[0:10],headers=headers))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x16 = sorted(x15, key=itemgetter(6,7))  #Sort by date, lat, and then lo\n",
    "x16a = np.array(x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"GLat1\",\"GLon1\",\"GLat2\",\"GLon2\",\"CLat\",\"CLon\"]\n",
    "print(tabulate(x16a[0:10],headers=headers))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_loc = pd.DataFrame({'Glat': x15[:,6],'Glon': x15[:,7]})\n",
    "forecast_ws1 = pd.DataFrame({'Glat':fdata2a[:,1],'Glon':fdata2a[:,2],'WindSpeed':fdata2a[:,3],'Date':fdata2a[:,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_ext1 = pd.merge(station_loc, forecast_ws1, on=['Glat', 'Glon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forext1 = np.array(forecast_ext1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Lat\",\"Lon\",\"WindSpeed\",\"Date\"]\n",
    "print(tabulate(forext1[0:200],headers=headers))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x13a=np.array(x13)\n",
    "observation_ob1 = pd.DataFrame({'Glat':x13a[:,6],'Glon':x13a[:,7],'WindSpeed':x13a[:,13],'Date':x13a[:,9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_ext1 = pd.merge(station_loc, observation_ob1, on=['Glat', 'Glon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsext1 = np.array(observation_ext1)\n",
    "headers = [\"Lat\",\"Lon\",\"WindSpeed\",\"Date\"]\n",
    "print(tabulate(obsext1[0:200],headers=headers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the observation file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Extract_Data_obsext1_pickle', 'wb') as f:\n",
    "    pickle.dump(obsext1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the forecast file out to a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Extract_Data_forext1_pickle', 'wb') as f:\n",
    "    pickle.dump(forext1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_ob1.to_excel(\"/home/jovyan/spire/Input_Data/observation_ob1.xlsx\")  # write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the observation file in from a file as an array with pickle\n",
    "with open('/home/jovyan/spire/Input_Data/Test_Extract_Data_obsext1_pickle', 'rb') as f:\n",
    "    obsext1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le as an array with pickle\n",
    "with open('/h#load the forecast file in from a fiome/jovyan/spire/Input_Data/Test_Extract_Data_forext1_pickle', 'rb') as f:\n",
    "    forext1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lass NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4) \n",
    "        self.weights2 = np.random.rand(4,1)                 \n",
    "        self.y = y\n",
    "        self.output = np.zeros(self.y.shape)\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "\n",
    " return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "\n",
    " return x*(1-x)\n",
    "\n",
    "#class needed to build the neural network\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    " def __init__(self, x, y, nodes):#nodes represents the number of hidden nodes in hidden layer \n",
    "\n",
    "  self.input = x\n",
    "\n",
    "  self.weights1 = np.random.rand(self.input.shape[1], nodes) \n",
    "\n",
    "  self.weights2 = np.random.rand(nodes,1) \n",
    "\n",
    "  self.y = y\n",
    "\n",
    "  self.output = np.zeros(self.y.shape)\n",
    "\n",
    " def feedforward(self):\n",
    "\n",
    "  self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "\n",
    "  self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "\n",
    " \n",
    "\n",
    " def backprop(self):\n",
    "\n",
    "# application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "\n",
    "  d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "\n",
    "  d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "# update the weights with the derivative (slope) of the loss function\n",
    "\n",
    "  self.weights1 += d_weights1\n",
    "\n",
    "  self.weights2 += d_weights2\n",
    "\n",
    "#1.we would decide the train and test data set.\n",
    "\n",
    "score=0\n",
    "\n",
    "x = forext1\n",
    "\n",
    "y = obsext1\n",
    "\n",
    "for a in range(10):\n",
    "\n",
    " x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state = 5)\n",
    "\n",
    "#x and y should be numpy array, x: collum is input node, row is sample size. y should be only one colume, row #number is the size of sample\n",
    "\n",
    " #train the model\n",
    "\n",
    " wind = NeuralNetwork(x_train,y_train,nodes)\n",
    "\n",
    " for i in range(10000):\n",
    "\n",
    "  wind.feedforward()\n",
    "\n",
    "  wind.backprop()\n",
    "\n",
    " #then we test it\n",
    "\n",
    " wind.input=x_test\n",
    "\n",
    " acscore=metrics.accuracy_score(y_test,wind.output)\n",
    "\n",
    " score += acscore\n",
    "\n",
    "print(score/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
